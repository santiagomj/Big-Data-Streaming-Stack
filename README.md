# Big Data Streaming Stack

![Example](./docs/stak_bigdata_arq.svg)

Big Data Streaming Stack es un conjunto de tecnolog칤as unificadas con Docker Compose cuyo
proposito es facilitar el aprendizaje de algunas tecnolog칤as como Delta Lake en modo on-premise.

## Dependencias

- Docker 20.10.7
- Docker Compose 1.29.2

**Nota**: Se recomienda usar docker en alguna distribuci칩n de linux para mayor agilidad al momento
de instalar el stack.

## Inicio R치pido

Clonar o descargar el repositorio:

`git clone https://github.com/santiagomj/Big-Data-Streaming-Stack.git`

Acceder por consola o alg칰n ambiente de desarrollo a la carpeta donde fue descargado
el repositorio y ejecutar docker compose:

`docker-compose up`

Creaci칩n de usuario Apache Superset

`docker exec -it superset superset-init`

## Servicios locales

- Control Center: <http://localhost:9021>
- Jupyter Notebook: <http://localhost:8888>
- Hue: <http://localhost:8889>
- Superset: <http://localhost:8088>
- Minio: <http://localhost:9001>

## Conexi칩n con Power BI 游늵 y Hive SQL 游냏

Este apartado es para aquellos usuarios que no desean  usar super set
si no power BI, para ello debemos hacer unas configuraciones adicionales:

### Instalaci칩n del ODBC (Open DataBase Connectivity)

Esta utilidad nos servir치 para conectarnos a  cualquier
base de datos sin importar el gestor que est칠 maejando la
aplicaci칩n.

Procedemos a descargar la utlidad en el siguiente link:

- <https://www.microsoft.com/en-us/download/details.aspx?id=40886>

Le damos click  en descargar y e instalamos, luego en windows nos vamos para la barra de tareas y en la barra de busqueda colocamos:

"Origenes de datos ODBC (64 bits)"

![barra](./docs/bar.png)

Una vez abierto la aplicacion le damos en add... o agregar:

![add](./docs/add.png)

Nos saldr치 un cuadro con los drivers que tenemos disponibles para
realiazar la conexi칩n, debemos de fijarnos en el que diga
**Microsoft Hive ODBC driver** y le damos click en finalizar.

Acontinuaci칩n nos aparecer치 una ventaja con estas caracteristicas:

![config](./docs/config.png)

Los campos que nos interesan son:

- **Data Source Name:** el cual tendr치 el nombre de nuestra conexi칩n, es
recomendable que sea memotecnico para  diferenciar los diferentes tipos de conexiones.

    Para este caso le colocamos **Hive_Connection**.

- **Host(s):** All칤 ir치 el host donde est치 localizado tu servicio de bases de datos.

    Como el proyecto se est치 trabajando en docker, es importante tener en cuenta donde est치 ubicado el host del servcio y el puerto.

    en este caso el host es: **localhost** y el puerto es: **10000**.

- **Database:** Aqui va el nombre de la Base de datos, por defecto es default, sin embargo si tienen una base de datos con un nombre diferente este debe de ir en este apartado.

- **Authentication/Mechanism:** Si su servicio posee algun tipo de autenticaci칩n especifica se debe de seleccionar alguna de las opciones con la se est치 auntenticando tu servicio.

    Para este caso es : **Username**

Los demas campos se dejan en blanco y procedemos a realizar click en **test**

si la conexi칩n fue exitosa nos aparecer치 un cuadro de texto con un **succes!**

![success](./docs/success.png)

Hecho esto le damos en **Ok**  y **Aceptar**, el gestor se cierra automaticamente.

### Conexi칩n con power BI Y OBDC 游늵

Procedemos con la creaci칩n de un nuevo proyecto en Power BI desktop.

Luego le damos click a obtener Datos, Otras, buscamos OBDC y conectar:

![powerbi](./docs/pbi.png)

Nos aparecer치 un cuadro pidiendonos usuario y contrase침a.
Para ello es importante revisar en el [docker-compose.yml](docker-compose.yml) en el servicio llamado hive-server,
encuentras unas variables de entorno llamadas **HDFS_CONF_fs_s3a** en ellas encuentras una con **access_key** y **secret_key**, las cuales juegan el papel del usuario y password respectivamente, con esta informaci칩n puedes realizar la conexi칩n.

- **username**: crypto-prices.
- **password**: crypto-prices.

![creden](./docs/creden.png)

**IMPORTANTE**: Las tablas que se ven a continuaci칩n, no estan definidas inicialmente en el Docker Compose, por lo que inicialemnte, no existir치 ninguna tabla en la base de datos "default". dichas tablas se pueden crear con Apache Hive (Desde la interfaz de Hue) como tablas externas, en el archivo commands.txt se encuentran algunos comandos que pueden ser de ayuda para crear tablas externas.

No saldr치 el navegador, desde all칤 nos dirijimos a **HIVE**, **default** o el nombre de tu base de datos, **selecionas** las tablas que deseas trabajar y finalmente en **cargar**, tendr치s tus datos cargados y listos para trabajar con **power BI**.

![data](./docs/data.png)
