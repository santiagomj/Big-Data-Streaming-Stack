{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from delta import *\n",
    "from confluent_kafka.schema_registry import SchemaRegistryClient\n",
    "from pyspark.sql.avro.functions import from_avro\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-avro_2.12:3.0.1,org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.1,org.apache.spark:spark-streaming-kafka-0-10_2.12:3.0.1,io.delta:delta-core_2.12:0.8.0,com.amazonaws:aws-java-sdk:1.11.950,org.apache.hadoop:hadoop-aws:3.2.0,net.java.dev.jets3t:jets3t:0.9.4 pyspark-shell'\n",
    "\n",
    "builder = pyspark.sql.SparkSession.builder \\\n",
    "    .appName(\"kafka-delta-app\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"fs.s3a.path.style.access\", True) \\\n",
    "    .config(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"com.amazonaws.services.s3.enableV4\", True) \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Dcom.amazonaws.services.s3.enableV4=true\") \\\n",
    "    .config(\"fs.s3a.access.key\", \"crypto-prices\") \\\n",
    "    .config(\"fs.s3a.secret.key\", \"crypto-prices\") \\\n",
    "    .config(\"fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema_registry_conf = {'url': \"http://schema-registry:8081\"}\n",
    "\n",
    "schema_registry_client = SchemaRegistryClient(schema_registry_conf)\n",
    "schema_response = schema_registry_client.get_latest_version(\"crypto-prices\" + \"-value\").schema\n",
    "schema = schema_response.schema_str\n",
    "\n",
    "kafka_topic_name = \"crypto-prices\"\n",
    "kafka_bootstrap_servers = 'kafka:9092'\n",
    "\n",
    "dsraw = spark \\\n",
    "        .readStream \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers) \\\n",
    "        .option(\"subscribe\", kafka_topic_name) \\\n",
    "        .option(\"startingOffsets\", \"earliest\") \\\n",
    "        .option(\"failOnDataLoss\", \"false\") \\\n",
    "        .load()\n",
    "\n",
    "from_avro_options= {\"mode\":\"PERMISSIVE\"}\n",
    "\n",
    "ds = (\n",
    "  dsraw\n",
    "  .select(from_avro(expr(\"substring(value, 6, length(value)-5)\"), schema, from_avro_options).alias(\"value\"))\n",
    "  .selectExpr(\n",
    "      \"value.id\", \n",
    "      \"value.rank\", \n",
    "      \"value.symbol\", \n",
    "      \"value.name\", \n",
    "      \"value.supply\", \n",
    "      \"value.maxSupply\", \n",
    "      \"value.marketCapUsd\", \n",
    "      \"value.volumeUsd24Hr\", \n",
    "      \"value.priceUsd\", \n",
    "      \"value.changePercent24Hr\", \n",
    "      \"value.vwap24Hr\", \n",
    "      \"value.explorer\") \\\n",
    ")\n",
    "\n",
    "delta_table = ds.writeStream \\\n",
    "  .format(\"delta\") \\\n",
    "  .outputMode(\"append\") \\\n",
    "  .option(\"checkpointLocation\", \"/delta/events/_checkpoints/etl-from-json\") \\\n",
    "  .start(\"s3a://crypto-prices/events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crypto_prices = spark.read.format(\"delta\").load(\"s3a://crypto-prices/events\")\n",
    "crypto_prices.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Leer y ver en consola en real time el streaming\n",
    "# stream2 = spark.readStream.format(\"delta\").load(\"events\").writeStream.format(\"console\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
